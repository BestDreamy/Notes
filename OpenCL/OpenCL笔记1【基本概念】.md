# OpenCL笔记1【基本概念】

OpenCL是一个通用的异构计算模型，提供C语言接口，可以通过C扩展语法进行编程，从而实现**并行化**的**异构计算**。

> 向量化指这样一种概念：将一条指令复制多份从而在多个硬件上并行计算，以下面的C程序为例
>
> ```c
> int32_t a[4];
> int32_t b[4];
> int32_t c[4];
> //省略中间代码
> for(uint8_t i = 0; i < 4; i++)
> {
>     c[i] = a[i] + b[i];
> }
> ```
>
> 这是4个32位整数进行加法的程序
>
> 在最经典的五级流水线通用CPU上，它要执行4个时钟周期才能完成`c[i]`的计算；但对于向量化计算设备，可以将语句改写成如下形式：
>
> ```c
> _int256_m a;
> _int256_m b;
> _int256_m c;
> 
> c = a + b;
> ```
>
> 它将四个32位整数合并成256位向量，使用专用的向量加法器运算，就可以把四个周期才能完成的程序缩减成一个周期完成，从而提高计算速度

OpenCL最早由苹果公司提出，随机得到了AMD、IBM、Intel、Nvidia等公司的支持，2008年12月8日，OpenCL 1.0标准发布；2013年11月19日，OpenCL 2.0发布。这是一套通用的API，旨在减轻开发人员的编程难度，并提高程序的可移植性。目前OpenCL不仅支持Nvidia、AMD的GPGPU，也支持部分厂商的CPU、DSP、FPGA，以及任何在编译器级支持OpenCL标准的通用/向量化计算设备。

> Intel就让其大部分通用CPU设备和加速卡都支持了OpenCL，因此可以将同一份代码部署在CPU或其他Intel硬件加速卡上

OpenCL的基本架构被分成以下几部分：

* **平台模型Platform Model**：底层硬件的抽象描述，是对异构平台指令集和并行化（向量化）计算单元的封装
* **存储器模型Memory Model**：对异构平台共享/私有存储器的抽象模型，与平台模型一起为上层应用提供计算资源
* **执行模型Execution Model**：管理平台模型和存储器模型的指令框架，通过多种并行机制实现异构计算
* **编程模型Programming Model**：OpenCL的代码层**kernel**的实现模型，在主机端调用执行模型提供的资源

这四个模型相互解耦但存在依赖关系

> *Kernel就是OpenCL可执行代码的统称，也可以理解成OpenCL版本的“Cuda核函数”*
>
> Cuda核函数规定Nvidia GPU的各个线程访问哪个数据并执行什么计算
>
> Kernel就规定了某个特定设备上某个计算单元访问哪个存储器单元并执行什么计算

从编程模型方面看，OpenCL有点类似于OpenMP，支持并行化的编程思想，但是它的并发单位是`work-item`，每个work-item都会执行kernel（OpenCL的代码实例），有点类似于一个硬件执行器，使用时会把这些work-item映射到底层硬件，因此它能实现比OpenMP更细粒度的并行化控制，但也更不容易控制。

从执行模型方面看，OpenCL很接近某些GPU的硬件模型，它支持对硬件隔离的**上下文**机制，从而让每个kernel内部的数据处理过程不会出错。同时OpenCL还支持命令队列机制，这就是数据流处理的思想：Kernel把指令**提交**到设备，交给设备对应的计算硬件和内存去处理，这个队列甚至允许多发射和乱序执行。

从存储器模型方面看，OpenCL支持向量化的数据（被存入buffer对象）和矩阵化的数据（被存入image对象），但是矩阵化的数据需要依赖于硬件设备，它不像向量数组那样可以被直接引用。GPU往往可以很好地支持image运算

> 你听说过Tensor吗？张量（Tensor）是对矩阵概念的扩展，允许比二维、三维更高的维度。
>
> 一个图像可以用三个独立的数据（更数学一点，可以称这些数据正交）表示，包含了它的宽度、长度、色彩通道；但在其他领域中（比如机器学习或科学计算），经常要处理不止一张图片或一篇文档，因此需要使用四维张量来描述数据，除了以上三个数据，还需要指定一个样本量，对于语音、有效质量乃至高维的哈密顿量这些数据，都需要更深的**维度**（dimension）去描述，张量就是一个包含了很多维度（是人为划分出来的）信息的高维矩阵
>
> image就是为了更好地描述Tensor而出现的

从平台模型方面看，每个OpenCL设备会含有一个或多个**计算单元**（Compute Units），每个CU又由一个或多个**处理单元**（Processing Elements）构成，PU是设备上执行数据计算的最小单元，编程模型的`work-item`就被映射到这些PU上

> 之所以这么做的原因主要是为了平衡实际存储器和存储器模型与计算设备的对应关系，在后面的文章中再讲述

## 并行化



### 并行化计算模型







### 并行化硬件





## 异构计算





### 内存模型









### 平台模型





