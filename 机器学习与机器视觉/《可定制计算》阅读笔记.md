# 《可定制计算》阅读笔记

本笔记以基础概念为线索编写，黑体部分是关键字

* **登纳德缩放定律**：晶体管在满足内电场恒定（即每代芯片的供电电压降低30%）条件下，晶体管尺寸每代（约两年）减少30%。

    结合该定律和摩尔定律可得推论：晶体管密度每代翻倍，同时晶体管延时降低30%，功耗降低50%，能耗降低65%

    换句话说，同面积下能集成晶体管的数目翻倍，带来功耗和频率的翻倍，就好像同面积的电路被缩放到原来的1/4

    但是到21世纪早期，由于量子效应，晶体管漏电功耗显著增加，登纳德定律逐渐失效

* **定制计算**：调整处理器结构以使其适应于某种特定应用领域的技术

    面对登纳德缩放定律失效、摩尔定律放缓，定制计算技术成为提高计算效率的关键技术之一
    
    往往可重构的定制计算电路可以使得能效得到1~2个数量级提升；而专用于某个领域的定制计算电路有时能够实现数百万倍的能效提升；同时引入*可重构性*并利用*可整合*的硬件加速其可以解决适用范围过窄的问题，现在常见的DSA（异构计算）就是这个思路的延伸
    
* **暗硅**：在多核cpu中并不是所有核心都会被使用，往往同时工作的只有其中小部分核心，其他核心因为功耗、发热等问题往往得不到应用，这部分电路被称为暗硅

* **通用片上多处理器**（Chip MultProcessor，CMP）：具有通用性的计算处理器，常见的CPU，如i9 11900k、r5 5600x等具有多核心的桌面级cpu都属于这个类型

* **可定制异构平台**（Customizable Heterogeneous Platform，CHP）：用于提供定制化计算服务的可定制的SoC

    一般CHP中包含四个部件：

    * 用于通用计算和控制逻辑的**处理器核**
    * 用于定制计算的硬件**加速器**
    * 用于辅助计算和低功耗控制的**协处理器**
    * 存储数据和程序的**片上存储部件**

* **可重构硬件**：流片之后依然可以被灵活调整的硬件

    硬件可以被重构的程度取决于重构的粒度，越小的重构粒度灵活性越大，但一般会造成性能下降和能效降低等额外开销

    传统的可重构硬件只有FPGA一种，它算作可细粒度重构的硬件，因此会比同算法的ASIC实现有更低的速率和更高的开销

* **专用加速器**：针对特定领域内有限的一组应用或算法进行优化的硬件

    早期的GPU、图像数据编解码器、加解密加速器等都属于加速器

* **动态处理器核缩放和去特征化**：选择性停用处理器核中的部件来节省能耗

    通用的做法是在内核中引入特定机器的寄存器，用来指示特定部件是否激活

    stm32f4的dsp和fpu就使用了这样的技术

* **处理器核融合**：使一个大核能够像真正的许多小核叠加工作一样的体系结构，可以动态适应不同数量的线程级或指令级的并行处理

    通过将处理器核拆成两部分实现：一个是窄发射宽度的常规处理器核，但是它的取指模块（Fetch Module）会被舍弃；另一部分是充当模块化的取指/译码/派发模块的额外部件，负责为每个处理器核心执行取指指令，或统一为多个处理器核提供指令。取指模块会使用宽读取引擎读取整个指令块并将它们分发给各个核心，流水线结束后，通过一个排序流水线步骤来让指令顺序写回

* **定制指令集扩展**：用特定工作负载中的新指令来让处理器快速分派任务到计算模块

    intel的AVX-512指令集就是这样增强CPU性能的（可惜并不怎么实用）

    商用处理器常使用的就是像SSE和AVX这种专用*向量指令*形式，允许简单的指令操作大量数据。现代高性能处理器一般都采用超标量架构，它能够实现指令集层面的并行化处理，利用的是**单指令多数据流**（SIMD）指令，也就是所谓的向量指令。为了通过一个指令控制多个数据的处理，需要引入一组新的寄存器和一组用于执行向量并行计算的ALU。x86指令集中，向量指令在4~16个元素的小向量上运行，主要用于执行浮点运算。超标量处理器还引入了基于通道的设计：多个小型计算引擎和寄存器元素并行参与计算，发出一条向量指令，所有通道都会接收该指令，因此可以并行化地执行大量重复计算的任务

    定制扩展指令集还可以通过*定制计算引擎*实现——一般的ALU只有乘法、加法、移位等功能，但是可以通过改变流水线的方式塞进乘除法器乃至专用的矩阵点乘叉乘电路

    *可重构指令集*也是其中一个解决方案，它允许程序编写自己的指令，但是往往需要编译器对定制指令支持才可行

* **松耦合加速器**：独立于处理器内核运行的粗粒度加速器，是与核心交互但是不固定在核上的粗粒度计算引擎，简称LCA

    LCA可以部署在片上或片外，PC上的cpu+显卡组合就是一个广义上的LCA架构；片上LCA没有物理邻接某个特定核心，但是可以被系统中所有核心共享，LCA通过一个简单快速的控制逻辑电路（最常见的就是DMA）拉控制数据输入输出。但是LCA只能使用ASIC方式实现，这就导致LCA必须具有以下特性：1. 算法足够成熟；2. 算法需要算力较大或比较重要。DPU、APU等针对AIoT领域的SoC就可以理解成采用了LCA架构

    多核共享的LCA需要加入仲裁开销，一般存在软件和硬件两种仲裁方法。

    特别地，LCA不依赖编译器，而依赖开放给开发者的API，比如OpenCL就是一种面向通用计算的API架构；而Cuda-C++是NVidia开发的针对自家GPU的API接口；其他的硬件加速设备也会有针对性的接口，最大的阻碍就是它们往往不兼容

* **现场可编程硬件**：为通用性牺牲一些效率和性能的超细粒度可重构电路

* **粗粒度可重构阵列**：具有接近ASIC性能和具有一定可重构性的组合加速器























